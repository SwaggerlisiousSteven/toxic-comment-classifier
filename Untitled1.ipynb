{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...     -1   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...     -1   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...     -1   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...     -1   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.     -1   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0            -1       -1      -1      -1             -1  \n",
       "1            -1       -1      -1      -1             -1  \n",
       "2            -1       -1      -1      -1             -1  \n",
       "3            -1       -1      -1      -1             -1  \n",
       "4            -1       -1      -1      -1             -1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "df=pd.read_csv(\"\\\\Users\\\\visit\\\\OneDrive\\\\Desktop\\\\train1.csv\")\n",
    "df2=pd.read_csv(\"\\\\Users\\\\visit\\\\OneDrive\\\\Desktop\\\\test1.csv\")\n",
    "df3=pd.read_csv(\"\\\\Users\\\\visit\\\\OneDrive\\\\Desktop\\\\test_labels1.csv\")\n",
    "df2 = df2.merge(df3, how='left', on='id')\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this other one from 1897'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools, string, operator, re, unicodedata, nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import  RegexpTokenizer\n",
    "from nltk.corpus import words\n",
    "words = set(nltk.corpus.words.words())\n",
    "punc = list(set(string.punctuation))\n",
    "#df['comment_text'] = df['comment_text'].astype(str)\n",
    "def remove_punct(text):\n",
    "    no_punct = \"\".join([c for c in text if c not in punc])\n",
    "    return no_punct\n",
    "df['comment_text'] = df['comment_text'].apply(lambda x: remove_punct(x))\n",
    "df2['comment_text'] = df2['comment_text'].apply(lambda x: remove_punct(x))\n",
    "\n",
    "df2['comment_text'][16]\n",
    "#df['comment_text'][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bye Dont look come or think of back Tosser'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_nonenglish_words(text):\n",
    "    return \" \".join(w for w in nltk.wordpunct_tokenize(text) \n",
    "     if w.lower() in words or not w.isalpha())\n",
    "df['comment_text']= df['comment_text'].apply(lambda x: remove_nonenglish_words(x))\n",
    "\n",
    "df2['comment_text']= df2['comment_text'].apply(lambda x: remove_nonenglish_words(x))\n",
    "df['comment_text'][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bye', 'dont', 'look', 'come', 'or', 'think', 'of', 'back', 'tosser']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer= RegexpTokenizer(r'\\w+')\n",
    "df['comment_text']=df['comment_text'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "df2['comment_text']=df2['comment_text'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "df['comment_text'][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', '1897']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(text):\n",
    "    #words= [w for w in text if w not in stopwords.extend(['court','case','section','order','said', 'made'])]\n",
    "    words= [w for w in text if w not in stopwords.words('english')]\n",
    "    #words= [w for w in text if w not in stop]\n",
    "    return words\n",
    "df['comment_text']=df['comment_text'].apply(lambda x: remove_stopwords(x))\n",
    "df2['comment_text']=df2['comment_text'].apply(lambda x: remove_stopwords(x))\n",
    "#df['comment_text'][16]\n",
    "df2['comment_text'][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bye', 'dont', 'look', 'come', 'think', 'back', 'tosser']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def word_lemmatizer(text):\n",
    "    lem_text=[lemmatizer.lemmatize(i) for i in text]\n",
    "    return lem_text\n",
    "df['comment_text']=df['comment_text'].apply(lambda x: word_lemmatizer(x))\n",
    "df2['comment_text']=df2['comment_text'].apply(lambda x: word_lemmatizer(x))\n",
    "df['comment_text'][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 434123)\n",
      "  (0, 433318)\t0.2206378707491647\n",
      "  (0, 433313)\t0.14106277474656803\n",
      "  (0, 430660)\t0.18864749841470324\n",
      "  (0, 430364)\t0.08871846881960582\n",
      "  (0, 419887)\t0.4412757414983294\n",
      "  (0, 419805)\t0.2296001440322545\n",
      "  (0, 418868)\t0.1081129790954195\n",
      "  (0, 402215)\t0.13803497331002015\n",
      "  (0, 385332)\t0.06591302372362463\n",
      "  (0, 346119)\t0.16861565365148\n",
      "  (0, 340804)\t0.21710012533849227\n",
      "  (0, 324093)\t0.12742122811712703\n",
      "  (0, 323256)\t0.2200024258012215\n",
      "  (0, 321532)\t0.1858707869728123\n",
      "  (0, 321016)\t0.08037909652198023\n",
      "  (0, 288603)\t0.15451251870480842\n",
      "  (0, 249470)\t0.13336727650184058\n",
      "  (0, 249264)\t0.10176131816472603\n",
      "  (0, 241221)\t0.11716244102473676\n",
      "  (0, 224092)\t0.18128392774762317\n",
      "  (0, 223997)\t0.1023902225635829\n",
      "  (0, 208342)\t0.22496772119836383\n",
      "  (0, 208037)\t0.05879233821695138\n",
      "  (0, 196859)\t0.18287966584758394\n",
      "  (0, 196858)\t0.15881027009141901\n",
      "  :\t:\n",
      "  (153162, 126608)\t0.13139341216172756\n",
      "  (153162, 126518)\t0.20625378510304723\n",
      "  (153162, 126502)\t0.14074101197966646\n",
      "  (153162, 88148)\t0.13537323734883105\n",
      "  (153162, 64267)\t0.07856270425243936\n",
      "  (153162, 30891)\t0.08181295365451634\n",
      "  (153162, 28855)\t0.17101222941650654\n",
      "  (153162, 23641)\t0.2113715823059587\n",
      "  (153162, 23514)\t0.10707580092946414\n",
      "  (153162, 17076)\t0.17513592625288749\n",
      "  (153162, 16361)\t0.07829315716286013\n",
      "  (153163, 416849)\t0.1347740049022662\n",
      "  (153163, 416540)\t0.1664214220739092\n",
      "  (153163, 381659)\t0.344429683007995\n",
      "  (153163, 380886)\t0.11872072838481071\n",
      "  (153163, 360563)\t0.36935286283373625\n",
      "  (153163, 360541)\t0.1533025736530612\n",
      "  (153163, 277951)\t0.2925447545137579\n",
      "  (153163, 196210)\t0.3340856287790424\n",
      "  (153163, 196085)\t0.18323638684131446\n",
      "  (153163, 147022)\t0.39195546023036093\n",
      "  (153163, 146984)\t0.260111369226699\n",
      "  (153163, 123873)\t0.39195546023036093\n",
      "  (153163, 123369)\t0.17202925374221734\n",
      "  (153163, 24463)\t0.16189155399347324\n",
      "(153164, 6)\n",
      "        toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
      "0           1             1        1       1       1              1\n",
      "1           1             1        1       1       1              1\n",
      "2           1             1        1       1       1              1\n",
      "3           1             1        1       1       1              1\n",
      "4           1             1        1       1       1              1\n",
      "...       ...           ...      ...     ...     ...            ...\n",
      "153159      1             1        1       1       1              1\n",
      "153160      1             1        1       1       1              1\n",
      "153161      1             1        1       1       1              1\n",
      "153162      1             1        1       1       1              1\n",
      "153163      1             1        1       1       1              1\n",
      "\n",
      "[153164 rows x 6 columns]\n",
      "(4, 1)\n",
      "[[0.1]\n",
      " [0.2]\n",
      " [0.3]\n",
      " [0.4]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "loop of ufunc does not support argument 0 of type csr_matrix which has no callable exp method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: exp not found",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3d25e298e29b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m#pred_in = np.dot(inputs,weights) + bias#Feedforward output :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mpred_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#Backpropogation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m  \u001b[1;31m#Calculating error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_out\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtarget_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-3d25e298e29b>\u001b[0m in \u001b[0;36msigmoid\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;31m# Sigmoid function :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# Derivative of sigmoid function :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msigmoid_der\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# Main logic for neural network :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: loop of ufunc does not support argument 0 of type csr_matrix which has no callable exp method"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy.sparse import *\n",
    "X= df['comment_text'].astype('str')\n",
    "y = df.drop(labels = ['id','comment_text'], axis=1)\n",
    "X_1test = df2['comment_text'].astype('str')\n",
    "y_1test=df2.drop(labels = ['id','comment_text'], axis=1)\n",
    "y_1test = y_1test.abs()\n",
    "Y = label_binarize(y, classes=[0, 1, 2,3, 4,5])\n",
    "n_classes = Y.shape[1]\n",
    "#Y_1=mlb.fit_transform(y_1test)\n",
    "Y_1 = label_binarize(y_1test, classes=[0, 1, 2,3, 4,5])\n",
    "n_1classes = Y_1.shape[1]\n",
    "\n",
    "#multilabel_binarizer = MultiLabelBinarizer()\n",
    "#multilabel_binarizer.fit(y)\n",
    "#Y = multilabel_binarizer.transform(y)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(X) #features\n",
    "y = y\n",
    "X_1test = tfidf_vectorizer.transform(X_1test)#we dont want to fit twice, this will keep dimensions the same for training and testing\n",
    "#y_1test = y_1test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\visit\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:587: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9867143779258136\n",
      "test score: 0.3490180460160351\n",
      "precision score 0.819052460683186\n",
      "recall score 0.09087286713948335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "#from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "X_train= df['comment_text'].astype('str')\n",
    "y_train = df.drop(labels = ['id','comment_text'], axis=1)\n",
    "X_test = df2['comment_text'].astype('str')\n",
    "y_test=df2.drop(labels = ['id','comment_text'], axis=1)\n",
    "y_test = y_test.abs()\n",
    "#print(test)\n",
    "\n",
    "#multilabel_binarizer = MultiLabelBinarizer()\n",
    "#multilabel_binarizer.fit(y)\n",
    "#Y = multilabel_binarizer.transform(y)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X_train = tfidf_vectorizer.fit_transform(X_train) #features\n",
    "X_test = tfidf_vectorizer.transform(X_test)#we dont want to fit twice, this will keep dimensions the same for training and testing\n",
    "\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=200)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_predictions = mlp.predict(X_test)\n",
    "print ('train score:', mlp.score(X_train ,y_train))\n",
    "print ('test score:', mlp.score(X_test ,y_test))\n",
    "print('precision score', precision_score(y_test, y_predictions , average='micro'))\n",
    "print('recall score', recall_score(y_test, y_predictions , average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "n_classes=y.shape[1]\n",
    "# For each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test.iloc[:, i].values,\n",
    "                                                        y_predictions[:, i])\n",
    "    average_precision[i] = average_precision_score(y_test.iloc[:, i].values,  y_predictions[:, i])\n",
    "\n",
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_test.values.ravel(),\n",
    "     y_predictions.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(y_test,   y_predictions,\n",
    "                                                     average=\"micro\")\n",
    "print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n",
    "      .format(average_precision[\"micro\"]))\n",
    "\n",
    "plt.figure()\n",
    "plt.step(recall['micro'], precision['micro'], where='post')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\n",
    "    'Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n",
    "    .format(average_precision[\"micro\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import scikitplot as skplt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "vis_arr= np.asarray(multilabel_confusion_matrix(y_test, y_predictions))\n",
    "\n",
    "\n",
    "\n",
    "#labels = [\"\".join(\"c\" + str(i)) for i in range(0, 6)]\n",
    "labels= [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\",]\n",
    "\n",
    "\n",
    "\n",
    "def print_confusion_matrix(multilabel_confusion_matrix, axes, class_label, class_names, fontsize=14):\n",
    "\n",
    "    df_cm = pd.DataFrame(\n",
    "       multilabel_confusion_matrix, index=class_names, columns=class_names,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cbar=False, ax=axes)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    axes.set_xlabel('True label')\n",
    "    axes.set_ylabel('Predicted label')\n",
    "    axes.set_title(\"Confusion Matrix for the class - \" + class_label)\n",
    "    \n",
    "    \n",
    "fig, ax = plt.subplots(3, 2, figsize=(12, 7))\n",
    "    \n",
    "for axes, multilabel_confusion_matrix, label in zip(ax.flatten(), vis_arr, labels):\n",
    "    print_confusion_matrix(multilabel_confusion_matrix, axes, label, [\"Y\", \"N\"])\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
